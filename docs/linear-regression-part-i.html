<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Linear Regression - Part I | Statistics for Economics with R</title>
  <meta name="description" content="Chapter 1 Linear Regression - Part I | Statistics for Economics with R" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Linear Regression - Part I | Statistics for Economics with R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Linear Regression - Part I | Statistics for Economics with R" />
  
  
  

<meta name="author" content="Logan Kelly, Ph.D." />


<meta name="date" content="2020-12-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="linear-regression-part-ii.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics for Economics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="linear-regression-part-i.html"><a href="linear-regression-part-i.html"><i class="fa fa-check"></i><b>1</b> Linear Regression - Part I</a>
<ul>
<li class="chapter" data-level="1.1" data-path="linear-regression-part-i.html"><a href="linear-regression-part-i.html#r-packages-used-in-this-chapter"><i class="fa fa-check"></i><b>1.1</b> R Packages Used in this Chapter</a></li>
<li class="chapter" data-level="1.2" data-path="linear-regression-part-i.html"><a href="linear-regression-part-i.html#assumptions-of-the-classical-linear-regression-model"><i class="fa fa-check"></i><b>1.2</b> Assumptions of the Classical Linear Regression Model</a></li>
<li class="chapter" data-level="1.3" data-path="linear-regression-part-i.html"><a href="linear-regression-part-i.html#assumption-1.-linearity"><i class="fa fa-check"></i><b>1.3</b> Assumption 1. Linearity</a></li>
<li class="chapter" data-level="1.4" data-path="linear-regression-part-i.html"><a href="linear-regression-part-i.html#assumption-2-mean-of-the-residuals"><i class="fa fa-check"></i><b>1.4</b> Assumption 2: Mean of the residuals</a></li>
<li class="chapter" data-level="1.5" data-path="linear-regression-part-i.html"><a href="linear-regression-part-i.html#assumption-3-normally-distributed-residuals"><i class="fa fa-check"></i><b>1.5</b> Assumption 3: Normally distributed residuals</a></li>
<li class="chapter" data-level="1.6" data-path="linear-regression-part-i.html"><a href="linear-regression-part-i.html#case-study-1-how-risky-is-that-stock"><i class="fa fa-check"></i><b>1.6</b> Case Study 1: How risky is that stock?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linear-regression-part-ii.html"><a href="linear-regression-part-ii.html"><i class="fa fa-check"></i><b>2</b> Linear Regression - Part II</a>
<ul>
<li class="chapter" data-level="2.1" data-path="linear-regression-part-ii.html"><a href="linear-regression-part-ii.html#r-packages-used-in-this-chapter-1"><i class="fa fa-check"></i><b>2.1</b> R Packages Used in this Chapter</a></li>
<li class="chapter" data-level="2.2" data-path="linear-regression-part-ii.html"><a href="linear-regression-part-ii.html#assumptions-of-the-classical-linear-regression-model-1"><i class="fa fa-check"></i><b>2.2</b> Assumptions of the Classical Linear Regression Model</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression-part-ii.html"><a href="linear-regression-part-ii.html#assumption-4-multicollinearity"><i class="fa fa-check"></i><b>2.3</b> Assumption 4: Multicollinearity</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="linear-regression-part-ii.html"><a href="linear-regression-part-ii.html#the-hot-dog-case"><i class="fa fa-check"></i><b>2.3.1</b> The Hot Dog Case</a></li>
<li class="chapter" data-level="2.3.2" data-path="linear-regression-part-ii.html"><a href="linear-regression-part-ii.html#checking-for-multicollinearity"><i class="fa fa-check"></i><b>2.3.2</b> Checking for multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="linear-regression-part-ii.html"><a href="linear-regression-part-ii.html#testing-for-joint-significance"><i class="fa fa-check"></i><b>2.4</b> Testing for joint significance</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics for Economics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-regression---part-i" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Linear Regression - Part I</h1>
<script src=https://cdn.datacamp.com/datacamp-light-latest.min.js></script>
<script>var element =  $("div[class="book"]");element.classList.remove("with-summary");</script>
<div id="r-packages-used-in-this-chapter" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> R Packages Used in this Chapter</h2>
<p>Base R has a great deal of functionality, but the real power of R is that thousands of people developing packages that expand the capabilities of R. In his chapter we will be using the following packages.</p>
<ul>
<li><p><code>tidyverse</code> The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures (see <a href="https://www.tidyverse.org/" class="uri">https://www.tidyverse.org/</a>).</p></li>
<li><p><code>psych</code> A general purpose toolbox for personality, psychometric theory and experimental psychology (see <a href="https://cran.r-project.org/web/packages/psych/index.html" class="uri">https://cran.r-project.org/web/packages/psych/index.html</a>)</p></li>
</ul>
<p>The following code chunk test weather each package has been installed, installs the package if needed, and then loads the package.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="linear-regression-part-i.html#cb1-1" aria-hidden="true"></a><span class="cf">if</span> (<span class="op">!</span><span class="kw">require</span>(<span class="st">&quot;tidyverse&quot;</span>)) <span class="kw">install.packages</span>(<span class="st">&quot;tidyverse&quot;</span>)</span>
<span id="cb1-2"><a href="linear-regression-part-i.html#cb1-2" aria-hidden="true"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="linear-regression-part-i.html#cb1-3" aria-hidden="true"></a></span>
<span id="cb1-4"><a href="linear-regression-part-i.html#cb1-4" aria-hidden="true"></a><span class="cf">if</span> (<span class="op">!</span><span class="kw">require</span>(<span class="st">&quot;psych&quot;</span>)) <span class="kw">install.packages</span>(<span class="st">&quot;psych&quot;</span>)</span>
<span id="cb1-5"><a href="linear-regression-part-i.html#cb1-5" aria-hidden="true"></a><span class="kw">library</span>(psych)</span></code></pre></div>
<p><code>install.packages()</code> command installs the package and the <code>library()</code> command loads the package. For now, you can copy this code and paste this code to use it in your own analysis.</p>
</div>
<div id="assumptions-of-the-classical-linear-regression-model" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Assumptions of the Classical Linear Regression Model</h2>
<ol style="list-style-type: decimal">
<li>The dependent variable is <strong>linearly</strong> related to the coefficients of the model and the model is correctly specified.</li>
<li>The <strong>mean</strong> of the <strong>error</strong> term is <strong>zero.</strong></li>
<li>The error term is <strong>normally distributed.</strong> (Not absolutely necessary)</li>
<li>No perfect <strong>multicollinearity.</strong> No independent variable has a perfect linear relationship with any of the other independent variables.</li>
<li>The error term has a <strong>constant variance.</strong> No heteroscedasticity.</li>
<li>The error terms are <strong>uncorrelated</strong> with each other. No autocorrelation or serial correlation.</li>
<li>The <strong>independent variable(s)</strong> is/are <strong>uncorrelated</strong> with the equation <strong>error term.</strong></li>
</ol>
<p>In this chapter, we will focus on the first three assumptions, and we will discuss an important model diagnostic tool, the <em>residual vs. fit plot</em>.</p>
</div>
<div id="assumption-1.-linearity" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Assumption 1. Linearity</h2>
<p>To use linear regression, the relationship we are studying must be linear. Duh, right? But is is a very common mistake to assume linearity without checking. The best way to check is to plot the data using scatter plots. Let’s use a famous data set known as <em>Anscombe’s Quartet</em> as an example of identifying linear and non linear relationships. <em>Anscombe’s Quartet</em> is a set of four pairs of x/y data that all yield identical regression output.</p>
<p>Look at the summary statistics fro <em>Anscombe’s Quartet</em>.</p>
<div data-datacamp-exercise="" data-height="300" data-encoded="true">
eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIyBMb2FkIHBzeWNoIHBhY2thZ2VcbmlmICghcmVxdWlyZShcInBzeWNoXCIpKSBpbnN0YWxsLnBhY2thZ2VzKFwicHN5Y2hcIilcbmxpYnJhcnkocHN5Y2gpXG5cbiMjIExvYWQgYW5kIGRlc2NyaWJlIEFuc2NvbWJlJ3MgUXVhcnRldFxuZGF0YShcImFuc2NvbWJlXCIpXG5kZXNjcmliZShhbnNjb21iZSwgc2tldyA9IEYscmFuZ2VzID0gRikifQ==
</div>
<div class="code_note">
<p>The <code>data()</code> command loads built in R data sets. R has several built in data sets for learning R. <code>data("anscombe")</code> loads <em>Anscombe’s Quartet</em>.</p>
<p>The <code>describe()</code> command is from the <code>psych</code> package. You will sometimes see this indicated in documentation as follows: <code>psych::describe()</code> it does a nicer job of presenting summary statistics. The arguments skew and ranges are bothe set to false to keep the output simple.</p>
</div>
<p>Notice that the summary statistics fore each of the x’s and for each of the y’s are nearly identical. Now let’s look at the output from linear regression of the first and second x/y’s of the data set. In R, the <code>lm()</code> command is used to estimate linear regression models. The “lm” stands for linear model.</p>
<div data-datacamp-exercise="" data-height="300" data-encoded="true">
eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJhbnNjb21iZS5sbTAxIDwtIGxtKHkxIH4geDEsIGRhdGEgPSBhbnNjb21iZSlcbnN1bW1hcnkoYW5zY29tYmUubG0wMSlcbmFuc2NvbWJlLmxtMDIgPC0gbG0oeTIgfiB4MiwgZGF0YSA9IGFuc2NvbWJlKVxuc3VtbWFyeShhbnNjb21iZS5sbTAyKSJ9
</div>
<div class="code_note">
<p><code>lm()</code> is used to fit linear models. The first argument is the formula. the dependent variable is listed first followed by a <code>~</code>, i.e. a tilde. Then the independent, or predictor, variables are listed. The <code>+</code> (plus) sign is used to separate each independent variable. Note that the output of <code>lm()</code> is not very useful. You need to store the linear model in an object and then use the <code>summary()</code> to display the regression output.</p>
</div>
<p>Notice that the regression output for the first set of x/y’s is nearly identical to the second x/y’s, but before we draw any conclusions, let’s check that relationships are linear. We will do this by first plotting a scatter plot of x vs y for each pair. Then we will plot the <em>residue vs fit plot</em>.</p>
<p>To plot a scatter plot of x vs y for each pair we will use a tool from the <code>tidyverse</code> called <code>ggplot</code>.</p>
<div data-datacamp-exercise="" data-height="600" data-encoded="true">
eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImlmICghcmVxdWlyZShcImdncGxvdDJcIikpIGluc3RhbGwucGFja2FnZXMoXCJnZ3Bsb3QyXCIpXG5saWJyYXJ5KGdncGxvdDIpXG5pZiAoIXJlcXVpcmUoXCJkcGx5clwiKSkgaW5zdGFsbC5wYWNrYWdlcyhcImRwbHlyXCIpXG5saWJyYXJ5KGRwbHlyKSIsInNhbXBsZSI6ImFuc2NvbWJlICU+JSBnZ3Bsb3QoYWVzKHg9eDEseT15MSkpICtcbiAgZ2VvbV9wb2ludCgpICtcbiAgZ2d0aXRsZShcIlBsb3QxXCIpXG5cbmFuc2NvbWJlICU+JSBnZ3Bsb3QoYWVzKHg9eDIseT15MikpICtcbiAgZ2VvbV9wb2ludCgpICtcbiAgZ2d0aXRsZShcIlBsb3QyXCIpIn0=
</div>
<div class="code_note">

</div>
<p>To plot a scatter plot of x vs y for each pair we will use a tool from the <code>tidyverse</code> called <code>ggplot</code>.</p>
<div data-datacamp-exercise="" data-height="600" data-encoded="true">
eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImlmICghcmVxdWlyZShcImdncGxvdDJcIikpIGluc3RhbGwucGFja2FnZXMoXCJnZ3Bsb3QyXCIpXG5saWJyYXJ5KGdncGxvdDIpXG5pZiAoIXJlcXVpcmUoXCJkcGx5clwiKSkgaW5zdGFsbC5wYWNrYWdlcyhcImRwbHlyXCIpXG5saWJyYXJ5KGRwbHlyKVxuXG5hbnNjb21iZS5sbTAxIDwtIGxtKHkxIH4geDEsIGRhdGEgPSBhbnNjb21iZSlcbmFuc2NvbWJlLmxtMDIgPC0gbG0oeTIgfiB4MiwgZGF0YSA9IGFuc2NvbWJlKSIsInNhbXBsZSI6ImRhdDEgPC0gZGF0YS5mcmFtZShmaXQgPSBmaXR0ZWQoYW5zY29tYmUubG0wMSksXG4gICAgICAgICAgcmVzID0gcmVzaWQoYW5zY29tYmUubG0wMSkpXG5cbmRhdDEgJT4lIGdncGxvdChhZXMoeD1maXQseT1yZXMpKSArXG4gIGdlb21fcG9pbnQoKSArXG4gIGdndGl0bGUoXCJQbG90MVwiKVxuXG5kYXQyIDwtIGRhdGEuZnJhbWUoZml0ID0gZml0dGVkKGFuc2NvbWJlLmxtMDIpLFxucmVzID0gcmVzaWQoYW5zY29tYmUubG0wMikpXG5cbmRhdDIgJT4lIGdncGxvdChhZXMoeD1maXQseT1yZXMpKSArXG4gIGdlb21fcG9pbnQoKSArXG4gIGdndGl0bGUoXCJQbG90MlwiKSJ9
</div>
<div class="code_note">

</div>
</div>
<div id="assumption-2-mean-of-the-residuals" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Assumption 2: Mean of the residuals</h2>
<p>First exam the summary statistics of the residuals. Both the mean and the median should be very close to zero. Recalling the first of Anscombe’s Quartet.</p>
<pre><code>##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -1.92127 -0.45577 -0.04136  0.00000  0.70941  1.83882</code></pre>
<p>The mean and median of the residuals for the first of Anscombe’s Quartet looks good, but lest look at the second of the quartet.</p>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -1.9009 -0.7609  0.1291  0.0000  0.9491  1.2691</code></pre>
<p>Notice that the mean is zero, which is good, but the median is larger. While this is not a conclusive model diagnostic, it does trigger a red flag. Let’s examine the residuals vs. fit plot. We can see that that in Plot 1 the residuals are randomly spread around zero, but Plot 2 shows obvious pattern. In the case of the the second set of x/y pairs in Anscombe’s Quartet, the issue is that the relationship is non-linear.</p>
<div class="leftcol">
<p><strong>Plot 1</strong>
<img src="bookdownproj_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div class="rightcol">
<p><strong>Plot 2</strong>
<img src="bookdownproj_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<p>We can also use the standard error of regression, or what R calls the <code>Residual standard error</code>. The following function draws a little fancier residual vs. fit plot. It plots shaded regions corresponding to one and two standard errors of regression above and below zero. Most of the residuals should be within one standard error of regression plus or minus zero and nearly all residuals should be within plus or minus two standard error of regression of zero.</p>
<div data-datacamp-exercise="" data-height="600" data-encoded="true">
eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImlmICghcmVxdWlyZShcImdncGxvdDJcIikpIGluc3RhbGwucGFja2FnZXMoXCJnZ3Bsb3QyXCIpXG5saWJyYXJ5KGdncGxvdDIpXG5pZiAoIXJlcXVpcmUoXCJkcGx5clwiKSkgaW5zdGFsbC5wYWNrYWdlcyhcImRwbHlyXCIpXG5saWJyYXJ5KGRwbHlyKSIsInNhbXBsZSI6InBsb3QuZml0dGVkIDwtIGZ1bmN0aW9uKGxtb2QpIHtcbiAgZGYgPSBsbW9kJG1vZGVsXG4gIHRpdGxlID0gcGFzdGUoXCJSZXNpZHVhbHMgdnMuIEZpdHMgKERlcGVuZGVudCBWYXJpYWJsZTogXCIsXG4gICAgICAgICAgICAgICAgbmFtZXMoZGYpWzFdLFxuICAgICAgICAgICAgICAgIFwiKVwiLFxuICAgICAgICAgICAgICAgIHNlcCA9IFwiXCIpXG4gIHByIDwtIGRmICU+JSBnZ3Bsb3QoYWVzKHggPSBmaXR0ZWQobG1vZCksIHkgPSByZXNpZChsbW9kKSkpICtcbiAgICBnZW9tX3JpYmJvbihhZXMoeW1pbiA9IC1zaWdtYShsbW9kKSwgeW1heCA9IHNpZ21hKGxtb2QpKSxcbiAgICAgICAgICAgICAgICBmaWxsID0gXCJncmF5XCIsXG4gICAgICAgICAgICAgICAgYWxwaGEgPSAuNSkgK1xuICAgIGdlb21fcmliYm9uKGFlcyh5bWluID0gLXNpZ21hKGxtb2QpICogMiwgeW1heCA9IHNpZ21hKGxtb2QpICogMiksXG4gICAgICAgICAgICAgICAgZmlsbCA9IFwibGlnaHRncmF5XCIsXG4gICAgICAgICAgICAgICAgYWxwaGEgPSAuNSkgK1xuICAgIGdlb21fcG9pbnQoKSArXG4gICAgdGhlbWVfY2xhc3NpYygpICtcbiAgICBnZ3RpdGxlKHRpdGxlKSArXG4gICAgeWxhYihcIlJlc2lkdWxlc1wiKSArXG4gICAgeGxhYihcIkZpdHRlZFwiKSArXG4gICAgZ2VvbV9obGluZSh5aW50ZXJjZXB0ID0gMCxcbiAgICAgICAgICAgICAgIGxpbmV0eXBlID0gXCJzb2xpZFwiLFxuICAgICAgICAgICAgICAgY29sb3IgPSBcImJsYWNrXCIpXG4gIHJldHVybihwcilcbn1cblxuIyBFeGFtcGxlXG5cbmFuc2NvbWJlLmxtMDEgPC0gbG0oeTEgfiB4MSwgZGF0YSA9IGFuc2NvbWJlKVxucGxvdC5maXR0ZWQoYW5zY29tYmUubG0wMSApIn0=
</div>
</div>
<div id="assumption-3-normally-distributed-residuals" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Assumption 3: Normally distributed residuals</h2>
<p>This is one of the least important assumptions because linear regression is ver robust with respect to normality of the residuals. A great way to evaluate the normality assumption is to plot a histogram of the residuals. Plot 1 (left column) shows the residuals from the first of the x/y pairs in Anscombe’s Quartet. I have also plotted a normal cure over the histogram. The histogram is reasonably close to the normal curve.</p>
<p>By contrast, Plot 2 (right column) shows the residuals from the second of the x/y pairs in Anscombe’s Quartet. We have already shown that linear regression is not a good model for this data, and the non normality of the residuals is just one more symptom of that fact.</p>
<div class="leftcol">
<p><strong>Plot 1</strong>
<img src="bookdownproj_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
</div>
<div class="rightcol">
<p><strong>Plot 2</strong>
<img src="bookdownproj_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
<p>Here is a function that will help plot the histogram of the residuals.</p>
<div data-datacamp-exercise="" data-height="600" data-encoded="true">
eyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6IiMgaWYgKCFyZXF1aXJlKFwiZ2dwbG90MlwiKSkgaW5zdGFsbC5wYWNrYWdlcyhcImdncGxvdDJcIilcbiMgbGlicmFyeShnZ3Bsb3QyKVxuIyBpZiAoIXJlcXVpcmUoXCJkcGx5clwiKSkgaW5zdGFsbC5wYWNrYWdlcyhcImRwbHlyXCIpXG4jIGxpYnJhcnkoZHBseXIpIiwic2FtcGxlIjoicGxvdC5ub3JtYWwgPC0gZnVuY3Rpb24obG1vZCkge1xuICByZXMgPC0gcmVzaWQobG1vZClcbiAgaGlzdChyZXMsIHByb2JhYmlsaXR5ID0gVClcbiAgY3VydmUoXG4gICAgZG5vcm0oeCwgbWVhbiA9IG1lYW4ocmVzKSwgc2QgPSAoc2QocmVzKSkpLFxuICAgIGNvbCA9IFwiZGFya2JsdWVcIixcbiAgICBsd2QgPSAyLFxuICAgIGFkZCA9IFRSVUUsXG4gICAgeWF4dCA9IFwiblwiXG4gIClcbn1cblxuIyBFeGFtcGxlXG5cbmFuc2NvbWJlLmxtMDEgPC0gbG0oeTIgfiB4MiwgZGF0YSA9IGFuc2NvbWJlKVxucGxvdC5ub3JtYWwoYW5zY29tYmUubG0wMSApIn0=
</div>
</div>
<div id="case-study-1-how-risky-is-that-stock" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> Case Study 1: How risky is that stock?</h2>
<p>In this case study, we will use linear regression to calculate the beta of a particular stock.</p>
<p><strong>What is Beta?</strong> Beta is a measure of the volatility of a security or portfolio compared to the market as a whole. Volatility is a common measure of risk, i.e. the more volatile, or variable, the return of an asset are, the more risky the asset is considered to be.</p>
<p><strong>How is Beta Calculated?</strong> From the Capital Asset Pricing Model (CAPM), we have the following</p>
<p><span class="math display">\[R^e = RF+\beta(RM-RF)\]</span>
where <span class="math inline">\(R\)</span> is our stock, or portfolio, rate of return, <span class="math inline">\(RF\)</span> is the rate of return on a default risk free asset, and <span class="math inline">\(RM\)</span> is the market rate of return. Define <span class="math inline">\(R&#39;\)</span> to be our stock’s excess return, i.e. <span class="math inline">\(R-RF\)</span>, and <span class="math inline">\(RM&#39;\)</span> to be the market excess return, i.e. <span class="math inline">\(RM-RF\)</span>, then the linear model</p>
<p><span class="math display">\[R = \alpha + \beta (RM&#39;) + \epsilon\]</span>
can be used to estimate Beta. Under the CAPM assumptions, <span class="math inline">\(\alpha = 0\)</span> and <span class="math inline">\(\beta\)</span> is the stock, or portfolio, Beta.</p>
<p><strong>Enough theory. Let’s calculate a Beta.</strong> Let’s estimate the Beta for Tesla, Inc. (TSLA). To do so we need the following steps.</p>
<p><strong>Step 1. Get the data.</strong> We need stock price data for Tesla, the market return and the risk free rate of return. Use the S&amp;P 500 Index as the proxy for the market return and 3-month Treasury constant maturity as the risk free rate. The file stock.csv has the excess return for the S&amp;P 500 Tesla and Apple.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="linear-regression-part-i.html#cb4-1" aria-hidden="true"></a>stock.return &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/stock.csv&quot;</span>)</span>
<span id="cb4-2"><a href="linear-regression-part-i.html#cb4-2" aria-hidden="true"></a><span class="kw">head</span>(stock.return)</span></code></pre></div>
<pre><code>##        Date       AMZN      SP500        TSLA
## 1 11/2/2015  0.3905002  1.1802233  3.26119374
## 2 11/3/2015 -0.4850048  0.2724079 -2.57751655
## 3 11/4/2015  2.4703946 -0.3551667 10.59219611
## 4 11/5/2015  2.2675403 -0.1133064  0.06039556
## 5 11/6/2015  0.5657680 -0.0347682  0.25423925
## 6 11/9/2015 -0.5902068 -0.9871565 -3.07221284</code></pre>
<p><strong>Step 2. Estimate the model.</strong> We will first plot Tesla’s excess returns vs. the S&amp;P 500. Then we estimate the linear regression.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="linear-regression-part-i.html#cb6-1" aria-hidden="true"></a>beta.lm &lt;-<span class="st"> </span><span class="kw">lm</span>(TSLA <span class="op">~</span><span class="st"> </span>SP500, <span class="dt">data =</span> stock.return)</span>
<span id="cb6-2"><a href="linear-regression-part-i.html#cb6-2" aria-hidden="true"></a><span class="kw">summary</span>(beta.lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = TSLA ~ SP500, data = stock.return)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -20.417  -1.653  -0.105   1.469  17.073 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.15780    0.09325   1.692   0.0909 .  
## SP500        1.26545    0.07835  16.152   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.255 on 1218 degrees of freedom
## Multiple R-squared:  0.1764, Adjusted R-squared:  0.1757 
## F-statistic: 260.9 on 1 and 1218 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Step 2. Check the model.</strong> We need to check that the model does not violate the assumptions of linear regression. First we check for a linear relationship by plotting Tesla’s excess returns vs. the S&amp;P 500.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="linear-regression-part-i.html#cb8-1" aria-hidden="true"></a>stock.return <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>SP500,<span class="dt">y=</span>TSLA)) <span class="op">+</span></span>
<span id="cb8-2"><a href="linear-regression-part-i.html#cb8-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Next, we check the residuals vs. fit plot. We will use the <code>plot.fitted()</code> function we defined earlier. To use the function in your analysis, simply copy and past it into you R script.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="linear-regression-part-i.html#cb9-1" aria-hidden="true"></a><span class="kw">plot.fitted</span>(beta.lm)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>Finally, we check that the residuals are reasonably close to being normally distributed. We will use the <code>plot.normal()</code> function we defined earlier.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="linear-regression-part-i.html#cb10-1" aria-hidden="true"></a><span class="kw">plot.normal</span>(beta.lm)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-regression-part-ii.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/LJKelly3141/StatisticsForEconomics/edit/master/01_Regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/LJKelly3141/StatisticsForEconomics/blob/master/01_Regression.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
